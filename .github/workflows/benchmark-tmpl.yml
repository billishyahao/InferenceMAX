name: Template - Benchmark
on:
  workflow_call:
    inputs:
      runner:
        required: true
        type: string
      runner-script:
        type: string
        required: false
        default: ''
      image:
        required: true
        type: string
      model:
        required: true
        type: string
      framework:
        required: true
        type: string
      precision:
        required: true
        type: string
      exp-name:
        required: true
        type: string
      isl:
        required: true
        type: string
      osl:
        required: true
        type: string
      max-model-len:
        required: true
        type: string
      random-range-ratio:
        required: true
        type: string
      tp-list:
        required: true
        type: string
      run-benchmark:
        type: boolean
        required: false
        default: true
      run-accuracy-test:
        type: boolean
        required: false
        default: false
      conc-list:
        type: string
        default: '[4, 8, 16, 32, 64]' 

env:
  HF_TOKEN: '${{secrets.GITHUB_TOKEN}}'
  HF_HUB_CACHE: '/mnt/hf_hub_cache/'
  EXP_NAME: ${{ inputs.exp-name }}
  MODEL: ${{ inputs.model }}
  ISL: ${{ inputs.isl }}
  OSL: ${{ inputs.osl }}
  MAX_MODEL_LEN: ${{ inputs.max-model-len }}
  RANDOM_RANGE_RATIO: ${{ inputs.random-range-ratio }}
  IMAGE: ${{ inputs.image }}
  FRAMEWORK: ${{ inputs.framework }}
  PRECISION: ${{ inputs.precision }}
  RUN_ACCURACY_TEST: ${{ inputs.run-accuracy-test && 'true' || 'false' }}
  RUN_BENCHMARK: ${{ inputs.run-benchmark && 'true' || 'false' }}

jobs:
  benchmark:
    runs-on: ${{ inputs.runner }}
    timeout-minutes: 180

    strategy:
      fail-fast: false
      matrix:
        tp: ${{ fromJson(inputs.tp-list) }}
        conc: ${{ fromJson(inputs.conc-list) }}
    name: '${{ inputs.exp-name }} ${{ inputs.runner }} ${{ inputs.precision }} tp${{ matrix.tp }} conc${{ matrix.conc }}'

    env:
      TP: ${{ matrix.tp }}
      CONC: ${{ matrix.conc }}

    steps:
      - name: Resource cleanup
        run: |
          echo "[Docker] Skip Cleaning up resources ..."

      - uses: actions/checkout@v3
        with:
          token: '${{secrets.GITHUB_TOKEN}}'
          fetch-depth: 0

      - name: Launch job script
        env:
          RUNNER_NAME: ${{ runner.name }}
          RESULT_FILENAME: ${{ env.EXP_NAME }}_${{ env.PRECISION }}_${{ env.FRAMEWORK }}_tp${{ env.TP }}_conc${{ env.CONC }}_${{ runner.name }}
        run: |
          if [ -n "${{ inputs.runner-script }}" ]; then
            bash ./runners/${{ inputs.runner-script }}
          else
            bash ./runners/launch_${RUNNER_NAME%%_*}.sh
          fi
          FOUND_RESULT_FILE=
          for i in {1..10}; do
            if [ -f "$RESULT_FILENAME.json" ]; then
              echo "RESULT_FILENAME=${RESULT_FILENAME}" >> $GITHUB_ENV
              FOUND_RESULT_FILE=true
              break
            fi
            echo "Waiting for result file... (attempt $i)"
            sleep 1
          done
   
          if [ -z "$FOUND_RESULT_FILE" ]; then
            echo "Run failed: Benchmark result $RESULT_FILENAME.json not found." >&2
            exit 1
          fi

      - name: Process result
        if: ${{ inputs.run-benchmark }}
        run: |
          python3 utils/process_result.py ${{ inputs.runner }} $TP $RESULT_FILENAME $FRAMEWORK $PRECISION

      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.RESULT_FILENAME }}
          path: agg_${{ env.RESULT_FILENAME }}.json
